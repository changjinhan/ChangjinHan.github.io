---
title: "[Paper Review] 이번 주 AI/ML 논문 훑어보기 (26.02.02 ~ 02.08)"
excerpt: 자기진화·멀티에이전트·인간 영향까지
header:
    teaser: "assets/images/paper_review.jpg"
    overlay_image: "assets/images/paper_review.jpg"
    overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
    # caption: 
    actions:
        - url: 
use_math: true
toc: true
toc_sticky: true
toc_label: "페이지 목차"
categories: 
    - Paper Review
tags: 
    - Self Evolution
    - Agent
    - Research Automation
    - Skill Formation
    - Text to Image
date: 2026-02-09
---

이번 주 AI·ML 논문들을 쭉 훑어보다가,

이제는 단순히 모델을 키우는 시대가 아니라, **스스로 진화하고 협업하고, 인간에게 어떤 영향을 주는지까지 따지는 단계**로 넘어가고 있구나 하는 생각이 들었어요.

이번 글에서는 PyTorchKR에 소개된 논문들을 기반으로, 제가 직접 읽어보면서 느낀 흐름과 인사이트를 정리해보려고 합니다.

논문 하나하나를 세세하게 리뷰한다기보다는,

* 어떤 문제의식에서 나왔는지

* 우리 같은 개발자/연구자에게 어떤 의미가 있는지

* 당장 무엇을 시도해볼 수 있는지

이 관점으로 풀어볼게요.



## 🔍 이번 주 AI 논문 트렌드를 한 줄로 말하면?

이번 주 논문들을 관통하는 키워드는 제 기준에서 세 가지였습니다.

1. **데이터 없이 혹은 적은 데이터에서 스스로 진화하는 모델**

2. **단일 거대 모델보다, 여러 에이전트/도구를 잘 조율하는 시스템**

3. **성능을 넘어, 인간의 학습·연구·이해력에 미치는 영향까지 평가**

조금만 더 풀어보면 이렇습니다.

* Dr. Zero, SDPO 같은 연구는 **외부 정답지 없이 모델이 스스로 문제를 만들고, 틀리고, 고치면서 성장**하는 법을 탐구합니다.

* WideSeek-R1, SALE, DeepRead, PaperBanana, Idea2Story 같은 연구는 **여러 에이전트·도구를 설계하고 오케스트레이션하는 방향**으로 가고요.

* First Proof, SpatialGenEval, How AI Impacts Skill Formation은 **모델이 진짜로 이해하고 있는지, 그리고 그게 인간에게 무엇을 의미하는지**를 찔러봅니다.

이제 하나씩, 제 경험이랑 같이 풀어볼게요.



## 📚 문서 검색의 수준이 달라진다 – DeepRead

긴 PDF 문서에서 원하는 정보를 찾는 일, 다들 한 번쯤은 지옥을 겪어보셨을 겁니다.

저도 논문 읽을 때, 필요한 건 5페이지인데 PDF는 40페이지라서, 검색과 스크롤만 10분 넘게 하는 경우가 많아요.

[DeepRead 논문](https://arxiv.org/abs/2602.05014)은 이 문제를 꽤 정면에서 파고듭니다.

핵심 아이디어는 간단하지만 강력합니다.

* PDF를 그냥 텍스트 조각으로 잘라 쓰는 대신

* LLM 기반 OCR을 활용해 **섹션 구조, 단락 순서까지 살아 있는 Markdown**으로 변환

* 각 단락에 **좌표 메타데이터(어느 섹션, 몇 번째 단락인지)**를 붙입니다.

그리고 여기서 끝이 아니라, LLM에게 두 가지 도구를 줍니다.

1. **Retrieve**: 관련 있어 보이는 단락을 찾아오되, 그 단락의 구조적 위치 정보까지 같이 넘겨주는 도구

2. **ReadSection**: 특정 구간(섹션/단락 범위)을 **연속해서 읽게 하는 도구**

이 조합 덕분에 모델이 인간처럼 행동합니다.

먼저 위치를 잡고, 그다음 주변을 쭉 읽는 겁니다.

우리도 문서 볼 때, 목차 보고 섹션 찍고, 그 부분만 집중해서 보잖아요.

실험 결과도 Search-o1 스타일의 기존 에이전트형 검색보다 성능이 꽤 잘 나왔다고 하고요.

개인적으로 이 논문을 읽으면서 든 생각은:

* 앞으로 RAG 시스템을 설계할 때,\
  **문서를 단순 chunk로 쪼개는 방식은 점점 한계가 올 것 같다**

* 대신,

  * 문서 구조를 보존하는 프리프로세싱

  * 구조 좌표와 함께 검색하는 인터페이스

  * LLM에게 도구를 잘게 쪼개 제공하는 방식\
    이런 것들이 기본 옵션이 될 것 같다는 느낌이 들었습니다.

실제 구현을 보고 싶다면 프로젝트 페이지와 코드를 참고해보는 것도 좋겠습니다.\
(현재는 논문 위주라, 구현은 직접 만들어보는 재미가 있을 듯해요.)

논문 링크: [DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search](https://arxiv.org/abs/2602.05014)



## 🧠 작은 에이전트를 어떻게 "똑똑하게" 쓸 것인가 – SALE

개인적으로 제일 재밌게 본 논문 중 하나가 [SALE](https://arxiv.org/abs/2602.02751)입니다.

요즘 저도 소형 LLM + 대형 LLM 하이브리드 구성을 자주 쓰는데, 늘 드는 고민이 있습니다.

* 이 요청은 작은 모델로 처리해도 될까?

* 언제 큰 모델을 써야 할까?

* 이걸 사람이 규칙으로 다 박아 넣어야 하나?

SALE은 여기서 한 발 더 나아가, 아예 **에이전트들끼리 "전략 입찰"을 하게 만들어 버립니다.**

컨셉은 프리랜서 마켓과 비슷합니다.

* 여러 에이전트가 한 작업을 보고,

  * 자신이 어떻게 풀 건지 짧은 전략 계획을 제출

  * 그 전략이 성능 대비 비용 측면에서 얼마나 좋은지 평가

* 이 과정을 통해,

  * 어떤 에이전트가 맡을지 결정

  * 경매 메모리(공유 메모리)에 경험이 쌓이면서 **자기 개선**

흥미로운 지점은 두 가지였습니다.

1. **소형 에이전트만으로는 복잡한 작업에서 성능이 잘 안 늘어난다**는 점을, 실험으로 꽤 잘 보여준다는 것

2. 그렇다고 무조건 대형 모델로 도배할 필요는 없고,\
   **잘 설계된 전략 경매 시스템만으로도 대형 모델 의존도를 53% 줄이고, 비용도 35% 줄일 수 있었다**는 것

저는 이 논문이 주는 메시지가 꽤 현실적이라고 느꼈습니다.

* "작은 모델이 이렇게 뛰어납니다"가 아니라

* "작은 모델만으로는 부족하지만,\
  잘 조직된 시스템 안에서는 꽤 멀리 갈 수 있다"

마이크로서비스 아키텍처랑도 묘하게 닮았죠.

서비스 자체의 성능보다, **어떻게 나누고, 어떻게 조율하는지**가 더 중요한 구간으로 넘어가고 있다는 느낌이 들었습니다.

논문 링크: [Scaling Small Agents Through Strategy Auctions](https://arxiv.org/abs/2602.02751)



## 🧩 혼자 푸는 수학 난제, AI는 어디까지 왔나 – First Proof

[First Proof](https://arxiv.org/abs/2602.05192)는 수학자들 입장에서 상당히 도발적인 실험입니다.

간단히 말하면,

* 저자들이 실제 연구 과정에서 만났던\
  **연구급 난제 10개를 꺼내서**

* 아직 어디에도 공개하지 않은 상태로

* AI가 풀 수 있는지 시험해보자, 라는 프로젝트입니다.

재미있는 포인트는 이겁니다.

* 기존 수학 벤치마크는 대부분 **올림피아드, 교과서, 준비된 문제**에 기반

* 연구자가 실제로 겪는 문제의 모습과는 꽤 거리가 있음

* 게다가 요즘 LLM은 웹 검색도 잘하고, 기존 문헌을 뒤지는 능력도 좋아서\
  실제로 "새로운 걸 풀었는지"와 "검색 능력이 뛰어난지"를 분리하기가 점점 어려워지고 있습니다.

그래서 저자들은 아예 **인터넷에 없는 문제**로 시험장을 갈아엎은 셈입니다.

저는 이 흐름이 앞으로 되게 중요해질 거라고 생각합니다.

* 코딩 테스트도 이제는 GitHub에 있는 풀이 다 학습한 모델 상대로 해야 하고

* 수학도 기존 문제은행은 사실상 AI에게 거의 다 알려준 상황이니까요.

즉, **진짜 창의성, 진짜 연구 능력을 보려면 AI가 아직 보지 못한 문제를 준비할 수밖에 없다**는 것.

연구자 입장에서, 앞으로 이런 "비공개 벤치마크 컬렉션"이 분야별로 많이 생길 것 같다는 생각이 들었습니다.

논문 링크: [First Proof](https://arxiv.org/abs/2602.05192)



## 🤝 깊이 대신 넓이로 확장하는 검색 – WideSeek-R1

[WideSeek-R1](https://arxiv.org/abs/2602.04634)는 제목 그대로, **"폭 확장(width scaling)"**에 초점을 맞춘 프레임워크입니다.

기존의 많은 연구가

* 더 큰 모델

* 더 깊은 추론 체인

에 집중했다면, 이 논문은 질문을 이렇게 바꿉니다.

> "한 에이전트가 깊게 파고드는 대신,\
> 여러 에이전트가 병렬로 넓게 파고들면 어떨까?"

구조는 크게 세 가지입니다.

* **리드 에이전트**: 문제를 보고, 적절한 하위 작업들로 분해

* **여러 서브 에이전트**: 각 하위 작업을 병렬로 수행

* **공유 LLM + 분리된 컨텍스트**: 한 모델이지만, 각 에이전트가 독립적인 역할을 수행하게 설계

여기서 중요한 건, 이걸 단순한 핸드메이드 워크플로우로 짠 게 아니라는 점입니다.

**다중 에이전트 강화학습(MARL)**로 리드/서브 에이전트를 같이 훈련합니다.

결과도 꽤 인상적입니다.

* WideSeek-R1-4B가

* 거대한 단일 에이전트인 DeepSeek-R1-671B와

* 특정 벤치마크에서 비슷한 수준의 성능을 냅니다.

결국, **잘 orchestrate된 여러 명의 4B가 혼자 고군분투하는 671B를 따라잡은 셈**입니다.

저는 이 논문이 주는 메시지가 매우 실용적이라고 느꼈어요.

* 현실 서비스에서는

  * latency

  * 비용

  * 요청 폭주\
    등을 고려해야 해서, 거대 단일 모델을 항상 앞세울 수는 없습니다.

* 이럴 때,\
  "하나 더 큰 모델을 붙일까"가 아니라\
  "에이전트 구조를 한 번 더 고민해볼까?"라는 선택지가 생깁니다.

프로젝트 페이지와 코드도 공개되어 있으니,

* 멀티 에이전트 검색 시스템을 직접 만들어 보고 싶거나

* MARL 기반 오케스트레이션에 관심 있으신 분들은 살펴볼 만합니다.

프로젝트 페이지: [WideSeek-R1 홈페이지](https://wideseek-r1.github.io/)\
코드: [RLinf / WideSeek-R1 예제](https://github.com/RLinf/RLinf/tree/main/examples/wideseek_r1)

논문 링크: [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)



## 🎨 논문 그림, 직접 안 그려도 되는 시대? – PaperBanana

연구자나 개발자 분들 중에,

* 모델 구조 그림 그릴 때

* 실험 파이프라인 다이어그램 만들 때

도구 앞에서 멍하니 있는 경험, 다들 있으시죠.

개인적으로도 실험은 이미 다 해놓고, 마지막에 도표랑 그림 작업하다가 체력이 소진되는 경우가 많았습니다.

[PaperBanana](https://arxiv.org/abs/2601.23265)는 이 지점을 아주 직격합니다.

아이디어는 단순합니다.

* 최신 비전-언어 모델(VLM)과 이미지 생성 모델을 조합해서

* 여러 전문 에이전트를 둡니다.

  * 참고 그림 검색

  * 스타일/콘텐츠 설계

  * 이미지 생성

  * 자체 피드백 기반 수정

그리고 NeurIPS 2025 논문에서 실제 다이어그램을 뽑아\
**PaperBananaBench**라는 벤치마크도 만들었습니다.

여기서 기존 방법 대비

* 내용 충실도

* 간결함

* 가독성

* 미적 완성도

모두에서 더 좋은 점수를 받았다고 합니다.

이 논문이 흥미로운 이유는 두 가지였습니다.

1. "논문용 그림"이라는 엄청 구체적인 타깃에\
   LLM+VLM+에이전트를 꽤 정교하게 적용했다는 점

2. 통계 플롯 같은 **정량 그래프 생성**까지 확장 가능성을 보여준 점

저는 이걸 보면서,

> "앞으로는 실험과 글쓰기뿐 아니라,\
> 시각화까지 에이전트 워크플로우에 통으로 편입되겠구나"

라는 생각이 들었습니다.

프로젝트 페이지: [PaperBanana 데모 페이지](https://dwzhu-pku.github.io/PaperBanana/)\
코드: [PaperBanana GitHub](https://github.com/dwzhu-pku/PaperBanana)

논문 링크: [PaperBanana: Automating Academic Illustration for AI Scientists](https://arxiv.org/abs/2601.23265)



## 🧪 RL을 "자기 피드백"으로 하는 법 – SDPO

[SDPO](https://arxiv.org/abs/2601.20802)는 강화학습 + LLM 쪽에 관심 있는 분들에게 꽤 재미있는 포인트를 줍니다.

요즘 LLM 튜닝에서 많이 쓰는 패턴 중 하나가,

* 코드나 수학 같이

* 정답을 검증할 수 있는 도메인에서

* 보상 기반으로 RL을 돌리는 방식입니다.

문제는, 대부분 **시도당 스칼라 보상 하나**만 받는다는 점입니다.

* 성공: 1

* 실패: 0

이러면 "어디서 잘못됐는지"에 대한 정보가 거의 없어, **신용 할당(credit assignment)** 문제가 심각해집니다.

SDPO는 이렇게 묻습니다.

> 실패했을 때, 사실 런타임 에러 메시지나\
> 채점 시스템의 피드백이 같이 나오는데,\
> 이걸 왜 안 써?

그래서 제안하는 방향은 이렇습니다.

* 환경이 내주는 텍스트 피드백(에러, 설명 등)을\
  **밀집 학습 신호로 바꿔버리기**

* 현재 모델이 그 피드백을 입력으로 받게 해서,\
  그 상태에서 "다음 토큰 예측"을 하게 하고

* 그 분포를 다시 원래 정책에 **자기 증류(self-distillation)**

즉, 외부 교사를 따로 두지 않고,\
**피드백을 본 나 자신을 교사 모델로 삼는 셈**입니다.

흥미로운 결과 몇 가지를 꼽자면:

* 기존 RLVR 방식보다 **샘플 효율성과 최종 정확도가 둘 다 개선**

* 심지어 스칼라 보상만 주는 환경에서도,\
  디버깅 로그 등을 활용해 성능을 더 끌어올림

* 테스트 시 개별 질문에도 적용해서,\
  같은 성공 확률을 **3배 적은 시도로 달성**

읽으면서 이런 생각이 들었습니다.

* 앞으로 RL 세팅에서,\
  "보상 신호는 반드시 숫자일 필요가 없다"는 인식이 더 강해질 것 같고

* LLM이 이미 언어를 잘 다루니,\
  텍스트 피드백을 학습 신호로 직접 쓰는 패턴이 여기저기에서 튀어나올 듯합니다.

코드: [SDPO GitHub](https://github.com/lasgroup/SDPO)\
실험 로그: [SDPO Weights & Biases 프로젝트](https://wandb.ai/jonhue/SDPO)

논문 링크: [Reinforcement Learning via Self-Distillation](https://arxiv.org/abs/2601.20802)



## 🧱 공간 지능, 이미지 생성 모델의 진짜 약점 – SpatialGenEval

요즘 텍스트-투-이미지 모델 써보면,

* 스타일이나 화질은 기가 막힌데

* "의자가 테이블 왼쪽에 있고, 그 위에 컵이 있다" 같은 공간 관계는\
  종종 엉망일 때가 있습니다.

[SpatialGenEval](https://arxiv.org/abs/2601.20354)은 이 부분을 아주 집요하게 파고드는 벤치마크입니다.

구성은 이렇습니다.

* 25개의 실제 장면

* 1,230개의 길고 정보 밀도 높은 프롬프트

* 각 프롬프트마다

  * 10개의 공간 하위 도메인

  * 10개의 객관식 질의-응답 쌍

여기서 평가하는 건

* 물체의 위치와 배치

* 가림(occlusion)

* 인과 관계 등

실제로 21개의 최신 모델을 돌려본 결과,

* 고차원 공간 추론이 여전히 심각한 병목이라는 점이 다시 확인됩니다.

흥미로운 건, 이 벤치마크로 끝내지 않고\
**SpatialT2I라는 데이터셋도 같이 만들었다는 점**입니다.

* 15,400개의 텍스트-이미지 쌍

* 정보 밀도는 유지하되, 이미지와의 일관성을 강화한 프롬프트

이걸로 Stable Diffusion-XL, Uniworld-V1, OmniGen2를 파인튜닝 했더니,

* 각각 약 4~6% 정도의 꾸준한 성능 향상

* 공간 관계가 실제와 더 가까워지는 효과

즉, **공간 지능 부족은 모델 구조만의 문제가 아니라, 데이터 설계 문제도 크다**는 걸 보여주는 셈입니다.

코드: [SpatialGenEval GitHub](https://github.com/AMAP-ML/SpatialGenEval)

논문 링크: [Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models](https://arxiv.org/abs/2601.20354)



## 🧪 아이디어에서 논문까지, 오프라인 지식 그래프 – Idea2Story

요즘 "AI가 논문을 써준다"는 이야기가 심심찮게 나오는데,\
막상 써보면 느낌이 오죠.

* 문장은 그럴 듯한데

* 내용이 논문으로서의 구조, 방법론적 정합성이 부족한 경우가 많습니다.

[Idea2Story](https://arxiv.org/abs/2601.20833)는 이 문제를 꽤 흥미로운 각도에서 바라봅니다.

기존 접근은 대부분 이랬습니다.

* 런타임에 논문 잔뜩 읽고

* 요약하고

* 거기서 바로 연구 계획을 생성

이건 두 가지 문제가 있습니다.

1. 컨텍스트 윈도우 한계

2. 매번 똑같은 문헌을 다시 읽는 비효율

Idea2Story는 방향을 완전히 바꿉니다.

* 동료 평가를 거친 논문과 리뷰 피드백을 **지속적으로 수집**

* 거기서 **핵심 방법론 단위**를 추출

* 이걸 **재사용 가능한 연구 패턴**으로 쌓아 올리고

* 최종적으로 **방법론 지식 그래프**를 구성

런타임에는 이 지식 그래프를 기반으로,

* 사용자 아이디어를 적절한 연구 패러다임과 정렬시키고

* 해당 패턴들을 재조합해 연구 플랜과 스토리를 생성

저는 이 접근이 특히 마음에 든 이유가,

* "에이전트가 논문을 통째로 읽고 생각한다"는 환상을 버리고

* **연구 방법론 자체를 재사용 가능한 모듈로 본다는 점**이었습니다.

아키텍처적으로도,\
온라인 추론 부담을 오프라인 전처리로 미리 당겨놓는 형태라\
실무에서 응용할 여지도 많아 보입니다.

코드 데모: [Idea2Paper GitHub](https://github.com/AgentAlphaAGI/Idea2Paper)

논문 링크: [Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives](https://arxiv.org/abs/2601.20833)



## 🧑‍💻 AI가 초보 개발자의 성장을 가로막을 수 있을까 – Skill Formation

이 논문은 읽으면서 약간 뜨끔했습니다.

저도 코드 짤 때 AI 도움을 꽤 많이 쓰거든요.

[How AI Impacts Skill Formation](https://arxiv.org/abs/2601.20245)은\
AI 도구가 **초보 개발자의 "실제 성장"에는 어떤 영향을 주는지**를 직접 실험합니다.

설정은 이렇습니다.

* 참가자들에게 낯선 비동기 라이브러리(Trio)를 학습시키고

* 일부는 AI 도움을 받고, 일부는 받지 않게 한 뒤

* 개념 이해, 코드 읽기, 디버깅 능력을 측정

결과는 꽤 명확합니다.

* AI를 사용한 그룹은 **평균 17% 정도 더 낮은 점수**

* 완전히 AI에 코딩을 맡긴 사람들은

  * 생산성은 조금 올랐지만

  * 라이브러리에 대한 학습은 거의 안 됨

흥미로운 건, 연구진이 **여섯 가지 AI 사용 패턴**을 찾아냈다는 점입니다.

그 중 세 가지는

* 사람이 여전히 인지적으로 참여하면서

* AI를 도우미 수준으로 사용하는 패턴인데,

이 경우에는 **학습 결과가 꽤 잘 유지**됐습니다.

Anthropic에서 자세한 설명과 예시를 정리해둔 글도 있어서,\
AI 코딩 어시스턴트를 매일 쓰는 개발자라면 한 번쯤 읽어볼 만합니다.

해설 글: [How AI assistance impacts the formation of coding skills](https://www.anthropic.com/research/AI-assistance-coding-skills)

논문 링크: [How AI Impacts Skill Formation](https://arxiv.org/abs/2601.20245)

개인적으로 내린 결론은 이렇습니다.

* "AI를 쓰면 공부를 덜 해도 된다"가 아니라

* "AI를 쓰면서도 공부가 되게 쓰는 방법을 연구해야 한다"

저도 그래서 요즘은

* 먼저 제 힘으로 설계/틀을 잡고

* 코드나 테스트 작성에서 AI 도움을 받는 식으로\
  의식적으로 사용 패턴을 조정하고 있습니다.



## 🧬 훈련 데이터 없이 스스로 진화하는 검색 에이전트 – Dr. Zero

마지막으로 가장 강렬했던 논문 중 하나, [Dr. Zero](https://arxiv.org/abs/2601.07055)입니다.

주제는 이렇습니다.

> 고품질 훈련 데이터를 구하기 힘든 시대에,\
> 검색 에이전트가 **아예 데이터 없이 스스로 진화**할 수 있을까?

Dr. Zero의 프레임워크는 크게 두 역할로 나뉩니다.

* **제안자(Proposer)**: 다양한 질문을 생성

* **해결자(Solver)**: 그 질문에 답하면서 점점 나아지는 에이전트

둘 다 같은 베이스 모델에서 출발하고,\
서로를 밀어 올리는 피드백 루프를 형성합니다.

* 해결자가 점점 성장하면

* 제안자는 더 어렵지만 여전히 풀 수 있는 질문을 만들어야 하고

* 이게 자동 커리큘럼이 됩니다.

여기에 HRPO(hop-grouped relative policy optimization)라는 기법이 들어갑니다.

* 구조적으로 비슷한 질문들을 묶고

* 그룹 단위 기준선을 잡아서

* 각 질문의 난이도 평가에 필요한 샘플링 오버헤드를 줄이는 방식입니다.

핵심은, **계산량을 줄이면서도 학습 안정성과 성능은 유지**했다는 것.

놀라운 점은 결과입니다.

* 이렇게 **아무 훈련 데이터 없이** 자기 진화만 한 Dr. Zero가

* 완전 감독(supervised) 데이터로 학습된 검색 에이전트와\
  **비슷하거나 더 나은 성능을 보였다**는 점

코드도 공개되어 있으니,\
자기 진화형 에이전트에 관심 있는 분들은 꼭 한 번 뜯어볼 만합니다.

코드: [Dr. Zero GitHub](https://github.com/facebookresearch/drzero)

논문 링크: [Dr. Zero: Self-Evolving Search Agents without Training Data](https://arxiv.org/abs/2601.07055)

개인적으로는,\
"데이터 부족 시대 이후의 학습 패턴"을 엿본 느낌이었습니다.



## 🧭 정리하며 – 지금 우리에게 중요한 질문들

이번 주에 봤던 논문들을 하나로 묶어보면, 제 머릿속에는 이런 축이 그려졌습니다.

1. **스스로 진화하는 모델들**

   * Dr. Zero, SDPO, SALE

   * 데이터 없이 혹은 최소한의 정답으로\
     자기 피드백과 상호작용을 통해 성장하는 방향

2. **여러 에이전트와 도구를 조율하는 시스템들**

   * DeepRead, WideSeek-R1, PaperBanana, Idea2Story

   * 한 모델이 다 하는 게 아니라,\
     구조, 역할 분담, 지식 그래프, 도구 호출, 병렬화 같은\
     "조직 능력"이 성능의 핵심이 되는 시대

3. **평가와 인간 중심 관점**

   * First Proof, SpatialGenEval, How AI Impacts Skill Formation

   * 단순한 정답률을 넘어서

     * 연구 난제 해결 능력

     * 공간 지능

     * 인간의 학습과 성장에 미치는 장기적인 영향\
       을 진지하게 측정하려는 시도

개발자 입장에서 저는 이 세 가지 질문을 계속 품고 가야겠다는 생각이 들었습니다.

* 나는 지금 **모델 크기**에만 집착하고 있지는 않은가?

* 내 시스템은 **여러 도구/에이전트를 어떻게 조직할지** 고민하고 있는가?

* AI를 쓰면서, 나와 팀원들의 **실제 역량은 어떻게 변하고 있는지** 관찰하고 있는가?

앞으로는 "성능이 x% 올랐다"는 그래프보다,\
이런 질문에 답하는 논문과 시스템이 더 중요해질 것 같다는 느낌을 강하게 받았습니다.

---

이번 글에서는 PyTorchKR에 소개된 2월 첫째 주 AI/ML 논문들을,\
개발자이자 블로그 쓰는 사람 입장에서 한 번에 훑어보며 제 관점으로 재구성해봤습니다.

요약하자면, AI는 이제 **스스로 진화하고, 서로 협업하고, 인간의 학습과 연구 과정에 깊게 들어오는 단계**에 진입했습니다.\
우리는 이 변화 속에서, **모델만 보는 시야를 넘어서 시스템과 사람을 함께 보는 시야**를 가져야 할 때인 것 같습니다.
